# ml
ml class at the University of British Columbia 

#### jan - apr 2019

##### convolution (1d, 2d)
[convolution 1d](http://www.songho.ca/dsp/convolution/convolution.html#cpp_conv1d)\
[convolution 2d](http://www.songho.ca/dsp/convolution/convolution2d_example.html )

##### map
[map](https://www.probabilitycourse.com/chapter9/9_1_2_MAP_estimation.php)

##### basics
[basics of machine learning](https://leetcode.com/explore/learn/card/machine-learning-101/287/what_is_ml/1617/)\
[machine learning algorithm](https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/)\
[convexity](http://www.ee.bgu.ac.il/~haimp/it/lectures/append2_convex/ConvexFunctions.pdf)

##### algorithms

##### k-Nearest Neighbors

Pros: High accuracy, insensitive to outliers, no assumptions about data

Cons: Computationally expensive, requires a lot of memory
Works with: Numeric values, nominal values

##### Decision trees

Pros: Computationally cheap to use, easy for humans to understand learned results,
missing values OK, can deal with irrelevant features. 
The machine learning appears in how the decision tree is built

Cons: Prone to overfitting
Works with: Numeric values, nominal values

